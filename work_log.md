# Date 2021/2/16 
#### Work Detail
1. Write a top class's framework
2. Add some describe words...

#### Problem
1. What is the transformer model's output???
2. Whither the input's length should be know in the image segmentation transformer????

# Date 2021/2/17
#### work Detail
1. Finish the top class
2. Changed some input paramaters
3. Finish the Encoder class's framework
4. Finish the Decoder class's framework

#### Todolist
1. Finish the Encoder class(In here, we will add a position class)
2. Finish the Decoder class
3. Futher clearfy the transformer's workflow....

#### problem
1. How about the transformer's input look like
2. How about the transformer's output look like
3. How the embedding position work in transformer modul...

# Date 2021/2/18
#### work Detail
1. Finish the Attention class's framework
2. Finish the MLP class's framework
3. Finish the Embedding class's framework
4. Finish the Block class's framework
5. Finish the Embedding class and verfied these class's function...

#### Todolist
1. Finish the Attention class and verfy this class
2. Finish the MLP class and verfy this class
3. Finish the Block class and verfy this class
4. Finish the Encoder class and verfy this class

#### problem
Now there is no problem.....

# Date 2021/2/19
#### work Detail
1. Finish the Attention class and verified this class
2. Finish the MLP class and verified this class
3. Finish the Block class and verified this class
4. Finish the Encoder class and verified this class

#### Todolist
1. Finish the Naive decoder and verify
2. Finish the PUP decoder and verify
3. Finish the MLA decoder and verify

#### problem
1. Why the self-attention need the query , key , value
2. What is the transpose conv's detail workflow
3. Which loss function is fitted to train this model...
